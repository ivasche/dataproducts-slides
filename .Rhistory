x<-3
x<-data.frame(3)
View(x)
p1<-predict(fit,x,interval='prediction')
p1
p1<-predict(fit,x,interval="predict")
p1
fit.lm<-(mtcars$mpg~mtcars$wt)
predict(fit,x,interval="predict")
predict(fit.lm,x,interval="predict")
fit.lm<-lm(mtcars$mpg~mtcars$wt)
predict(fit.lm,x,interval="predict")
x<-data.frame(wt=3)
predict(fit.lm,x,interval="predict")
x
y<-mtcars$mpg
x<-mtcars$wt
fit<-lm(y~x)
newx<-data.frame(x=3)
predict(fit,x,interval="predict")
predict(fit,newx,interval="predict")
newx<-data.frame(mean(mtcars$wt))
predict(fit,newx,interval="predict")
predict(fit,newx,interval="confidence")
newx<-data.frame(x=mean(mtcars$wt))
predict(fit,newx,interval="confidence")
y<-mtcars$mpg
x<-mtcars$wt/2
fit<-lm(y~x)
?lm
?confint
confint(fit,x,0.95)
confint(fit,'x',0.95)
y<-mtcars$mpg
x<-mtcars$wt
sum((y-mean(y))^2)
d<-sum((y-mean(y))^2)
fit<-lm(y~x)
fit$residuals
n<-sum(fit$residuals^2)
n/d
require(caret)
library(caret)
install.packages("caret")
library(caret)
library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.97,list=F)
traiing<-spam[inTrain,]
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=F)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
set.seed(32343)
modelFit <- train(type ~.,data=training, method="glm")
modelFit
install.packages("e1071")
set.seed(32343)
modelFit <- train(type ~.,data=training, method="glm")
modelFit
modelFit$finalModel
predictions <- predict(modelFit,newdata=testing)
predictions
confusionMatrix(predictions,testing$type)
inTrain
-inTrain
!inTrain
set.seed(32323)
folds<-createFolds(y=spam$type,k=10,list=T,returnTrain=T)
sapply(folds,length)
folds[[1]][1:10]
folds<-createFolds(y=spam$type,k=10,list=T,returnTrain=F)
sapply(folds,length)
folds<-createResample(y=spam$type,times=10,list=T)
sapply(folds,length)
folds[[1]][1:10]
tme<-1:1000
folds<-createTimeSlices(y=tme,initialWindow=20,horizon=10)
ames(folds)
names(folds)
folds$train[[1]]
folds$train[[2]]
folds$train[[3]]
inTrain<-createDataPartition(y=spam$type,p=0.75,list=F)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
modelFit<-train(type~.,data=training,method="glm")
args(train.default)
install.packages("ISLR")
library(ISLR)
library(ggplot2)
data(Wage)
summary(Wage)
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=F)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training)
dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],y=training$Wage,plot="pairs")
featurePlot(x=training[,c("age","education","jobclass")],
y = training$wage,
plot="pairs")
qplot(age,wage,colour=jobclass,data=training)
qq<-qplot(age,wage,colour=education,data=training)
qq+geom_smooth(method=lm)
install.packages("Hmisc")
library(Hmisc)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
set.seed(13343)
# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
intsall.packages("RANN")
intsall.packages("RA NN")
intsall.packages("RA.NN")
install.packages("RANN")
library(ISLR); library(caret); data(Wage);
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass,data=training)
head(predict(dummies,newdata=training))
nsv <- nearZeroVar(training,saveMetrics=TRUE)
nsv
library(splines)
bsBasis <- bs(training$age,df=3)
bsBasis
lm1 <- lm(wage ~ bsBasis,data=training)
plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
predict(bsBasis,age=testing$age)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
?createDataPartition
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
inTrain
head(mixtures)
qplot(CompressiveStrength,data=mixtures)
plot(CompressiveStrength,data=mixtures)
plot(mixtures$CompressiveStrength)
?cut2
mixtures$ind1<-with(mixtures,cut2(FlyAsh,g=10))
View(mixtures)
plot(mixtures$CompressiveStrength,col=mixtures$ind1)
mixtures$ind2<-with(mixtures,cut2(Age,g=10))
plot(mixtures$CompressiveStrength,col=mixtures$ind2)
with(mixtrues,corr(CompressiveStrentgh,FlyAsh))
with(mixtures,corr(CompressiveStrentgh,FlyAsh))
with(mixtures,correlation(CompressiveStrentgh,FlyAsh))
??correlation
with(mixtures,cor(CompressiveStrentgh,FlyAsh))
with(mixtures,cor(CompressiveStrength,FlyAsh))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(SuperPlasticizer,data=mixtures,geom="density")
qplot(Superplasticizer,data=mixtures,geom="density")
qplot(log(Superplasticizer),data=mixtures,geom="density")
qplot(log(Superplasticizer+1),data=mixtures,geom="density")
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(adData)
?grep
grep("^IL",names(adData))
vars<-grep("^IL",names(adData))
adData[,vars]
preProc<-preProcess(adData[,vars],method="pca")
preProc<-preProcess(training[,vars],method="pca")
summary(preProc)
preProc
?preProc
?preProcess
preProc$numComp
preProc$std
preProc$std^2
sum(preProc$std^2)
sum(preProc$std^2[1:7])/sum(preProc$std^2)
sum((preProc$std[1:7])^2/sum(preProc$std^2)
sum((preProc$std[1:7])^2)/sum(preProc$std^2)
sum((preProc$std[1:8])^2)/sum(preProc$std^2)
sum((preProc$std[1:9])^2)/sum(preProc$std^2)
sum((preProc$std[1:10])^2)/sum(preProc$std^2)
preProc$rotation
preProc<-preProcess(training[,vars],method="pca",thresh=7)
preProc
preProc<-preProcess(training[,vars],method="pca",thresh=0.8)
preProc
vars<-grep("^IL|diagnosis")
vars<-grep("^IL|diagnosis",names(adData))
vars
trn<-training[,vars]
tst<-testing[,vars]
modelFit<-train(trn$diagnosis~.,method="glm",data=trn)
confusionMatrix(trn$diagnsis,predict(modelFit,tst))
confusionMatrix(trn$diagnosis,predict(modelFit,tst))
confusionMatrix(tst$diagnosis,predict(modelFit,tst))
trainPC<-predict(preProc,trn)
trainPC<-predict(preProc,training)
library(XML)
url<-"http://en.wikipedia.org/wiki/Body_mass_index"
table<-readHTMLTable(url)
table[[7]]
library(XML)
url<-"http://en.wikipedia.org/wiki/Body_mass_index"
table<-readHTMLTable(url)[[7]]
View(table)
grep("Relative",names(table))
!grep("Relative",names(table))
!grepl("Relative",names(table))
library(XML)
url<-"http://en.wikipedia.org/wiki/Body_mass_index"
table<-readHTMLTable(url)[[7]]
table<-table[,!grepl("Relative",names(table))][1:177]
library(XML)
url<-"http://en.wikipedia.org/wiki/Body_mass_index"
table<-readHTMLTable(url)[[7]]
table<-table[,!grepl("Relative",names(table))]
table<-table[1:177,]
View(table)
library(XML)
url<-"http://en.wikipedia.org/wiki/Body_mass_index"
table<-readHTMLTable(url)[[7]]
table<-table[,!grepl("Relative|Ratio|Average",names(table))]
table<-table[1:177,]
View(table)
table$Country[39]
table$Country[139]
table$Country[136]
sapply(table,class)
names(table)<-c("country","male","female")
library(XML)
url<-"http://en.wikipedia.org/wiki/Body_mass_index"
table<-readHTMLTable(url)[[7]]
table<-table[,!grepl("Relative|Ratio|Average",names(table))]
table<-table[1:177,]
names(table)<-c("country","male","female")
table$male<-as.numeric(as.character(table$male))
table$female<-as.numeric(as.character(table$female))
View(table)
sapply(table,class)
setwd("D:/Documents/Documents/Coursera/Developing Data Products/Project")
runApp()
library(shiny)
runApp()
runApp()
runApp()
runApp()
as.list(table$country)
runApp()
as.list(table$country)
names(as.list(table$country))
library(XML)
url<-"http://en.wikipedia.org/wiki/Body_mass_index"
table<-readHTMLTable(url)[[7]]
table<-table[,!grepl("Relative|Ratio|Average",names(table))]
table<-table[1:177,]
names(table)<-c("country","male","female")
table$country<-as.character(table$country)
table$male<-as.numeric(as.character(table$male))
table$female<-as.numeric(as.character(table$female))
shinyUI(pageWithSidebar(
headerPanel("Body Mass Index comparisons"),
sidebarPanel(
selectInput('country', 'Choose your country:', as.list(table$country)),
checkboxGroupInput("id2", "Checkbox",
c("Value 1" = "1",
"Value 2" = "2",
"Value 3" = "3"))
),
mainPanel(
)
))
runApp()
runApp()
runApp()
?list
runApp()
runApp()
list(c("Male","Female"))
list("Male","Female")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
round(2.48654857,2)
runApp()
?subset
url<-"http://en.wikipedia.org/wiki/Body_mass_index"
table<-readHTMLTable(url)[[7]]
table<-table[,!grepl("Relative|Ratio|Average",names(table))]
table<-table[1:177,]
names(table)<-c("Country","Male","Female")
table$country<-as.character(table$country)
table$male<-as.numeric(as.character(table$male))
table$female<-as.numeric(as.character(table$female))
url<-"http://en.wikipedia.org/wiki/Body_mass_index"
table<-readHTMLTable(url)[[7]]
table<-table[,!grepl("Relative|Ratio|Average",names(table))]
table<-table[1:177,]
names(table)<-c("Country","Male","Female")
table$Country<-as.character(table$Country)
table$Male<-as.numeric(as.character(table$Male))
table$Female<-as.numeric(as.character(table$Female))
View(table)
runApp()
runApp()
runApp()
runApp()
?return
?subset
x<-subset(table,select=input$sex)
x<-subset(table,select="Female")
View(x)
View(table)
View(x)
View(x)
x$Country<-table$Country
View(x)
runAPp()
runApp()
runApp()
?las
?par
?barplot
runApp()
?par
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
???pin
??pin
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?par
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?par
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?order
runApp()
runApp()
runApp()
?barplot
runApp()
runApp()
?par
runApp()
runApp()
runApp()
runApp()
runApp()
?col
?colors
runApp()
runApp()
?reactive
runApp()
?reactive
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?par
runApp()
runApp()
runApp()
install.packages("shinyapps")
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
shinyapps::setAccountInfo(
name="ivasche",
token="F237FD7532548C10B2832597BAA81F33",
secret="<SECRET>")
shinyapps::setAccountInfo(
name="ivasche",
token="F237FD7532548C10B2832597BAA81F33",
secret="DV4HuaVrW2GZ6DFH5n3yaex9QdwzpXPLfogJcm31")
runApp()
library(shiny)
library(shiny)
runApp()
deployApp()
deployApp()
runApp()
deployApp()
library(shiny)
deployApp()
library("shinyapps", lib.loc="C:/Users/Alexey Ivashchenko/Documents/R/win-library/3.0")
deployApp()
library(shiny)
library("shinyapps", lib.loc="C:/Users/Alexey Ivashchenko/Documents/R/win-library/3.0")
deployApp("project")
deployApp()
library(slidify)
author("BMI_project")
publish_github("ivasche","dataproducts-project")
?publish_github
publish_github("ivasche","test")
publish_github("ivasche","test")
publish_github("ivasche","test")
setwd("D:/Documents/Documents/Coursera/Developing Data Products/project/dataproducts-project")
author("slides")
author("slides")
library(slidify)
author("slides")
publish_github("ivasche","test")
